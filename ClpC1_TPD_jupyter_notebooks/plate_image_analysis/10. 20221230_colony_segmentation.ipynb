{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8e6707-9250-4e17-a889-c7949bc3d297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jz-rolling/Desktop/DeepLearningPilot\n"
     ]
    }
   ],
   "source": [
    "cd ~/Desktop/DeepLearningPilot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7512806a-0f08-465b-8142-39c855e6d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf,matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.transform import resize,rescale\n",
    "from skimage import measure, segmentation,morphology,filters,feature,exposure\n",
    "import tifffile\n",
    "import momia2 as mo\n",
    "from momia2.classify.classifier_helper import *\n",
    "import timeit\n",
    "import pickle as pk\n",
    "from tensorflow import keras\n",
    "from unet import *\n",
    "import glob, os\n",
    "import read_roi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f37437-2c81-43c1-90b1-628b268d2763",
   "metadata": {},
   "source": [
    "### Label training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73306d16-6934-4070-b155-72c9361358de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label images\n",
    "wd = '/Users/jz-rolling/Desktop/DeepLearningPilot/Myco_image_lib/colony_seg_training_set/'\n",
    "for roi in sorted(glob.glob(wd+'*.zip')):\n",
    "    n = roi.split('/')[-1].split('_roi.zip')[0]\n",
    "    mo.classify.roi2multimasks(wd+'{}_roi.zip'.format(n),\n",
    "                               image_file=wd+'{}.tif'.format(n),\n",
    "                               dst=wd+'{}_masks.tif'.format(n),\n",
    "                               erosion_radius=1)\n",
    "    mo.classify.roi2multilabel(wd+'{}_roi.zip'.format(n),\n",
    "                               image_shape=plt.imread(wd+'{}.tif'.format(n)).shape,\n",
    "                               dst=wd+'{}_multilabel.tif'.format(n),\n",
    "                               erosion_radius=1)\n",
    "# erosion_radius denotes the radius of the disk selem used to erode the mask and create edge pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b7fd0-4aa9-4bd2-897e-9139477e0a3a",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae40b8f-8d44-42aa-8595-bf064c8fcb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 15:06:47.245699: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-16 15:06:47.921942: E tensorflow/core/framework/node_def_util.cc:629] NodeDef mentions attribute validate_shape which is not in the op definition: Op<name=AssignVariableOp; signature=resource:resource, value:dtype -> ; attr=dtype:type; is_stateful=true> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node AssignNewValue}}\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/Users/jz-rolling/Desktop/DeepLearningPilot/ColonySeg_AttResUnet_20221230_3channel_256/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1dc9de-5535-47dd-bf64-9a09c8913fce",
   "metadata": {},
   "source": [
    "### Colony segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "3ed6b53b-26f8-453f-ab39-04c2ee10d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in sorted(glob.glob('/Volumes/JZSSD_temp/202212_Harry_plate_analysis/20221228_output/1_gridproj/*.zip')):\n",
    "    rois = read_roi.read_roi_zip(z)\n",
    "    header = z.split('/')[-1].split('_')[0]\n",
    "    plate_images = {}\n",
    "    out_fname = '/Volumes/JZSSD_temp/202212_Harry_plate_analysis/20221228_output/1_gridproj/{}.pred_results.pk'.format(header)\n",
    "    if not os.path.isfile(out_fname):\n",
    "        for f in sorted(glob.glob('/Volumes/JZSSD_temp/202212_Harry_plate_analysis/20221228_output/1_gridproj/{}/*.tif'.format(header))):\n",
    "            img_header = f.split('/')[-1].split('.')[0]\n",
    "            img = plt.imread(f)\n",
    "            img = mo.utils.dual_bandpass(img,min_structure_scale=1,max_structure_scale=50)\n",
    "            mask = img<filters.threshold_otsu(img)\n",
    "            img = normalize_image(img,mask=mask)\n",
    "            plate_images[img_header]=img\n",
    "\n",
    "        stack = np.array([x for k,x in plate_images.items()])\n",
    "        preds = {}\n",
    "        for k in rois.keys():\n",
    "            l,t,w,h = rois[k]['left'],rois[k]['top'],rois[k]['width'],rois[k]['height']\n",
    "            crop = stack[:,t:t+h,l:l+w]\n",
    "            pred = np.array([image2predict(im,model,size=256,pad=4,channels=3)[0] for im in crop])\n",
    "            preds[k] = np.concatenate([np.expand_dims(crop,-1),pred],axis=-1)\n",
    "\n",
    "        plate_images['Prediction'] = preds\n",
    "        pk.dump(plate_images,open(out_fname,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
