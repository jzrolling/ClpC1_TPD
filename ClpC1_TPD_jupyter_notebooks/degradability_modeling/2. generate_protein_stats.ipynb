{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42dbaf09-f9c9-4d82-99e2-9bde1f075d83",
   "metadata": {},
   "source": [
    "### Set up working env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5e9b0b5b-9ead-4e16-ae7f-df79d4fea3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rafm, pandas as pd, numpy as np,matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.gridspec import GridSpec as gs\n",
    "import pandas as pd\n",
    "from Bio.PDB.MMCIF2Dict import MMCIF2Dict\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib import colormaps\n",
    "from scipy.stats import mannwhitneyu as mwu, spearmanr,pearsonr\n",
    "import glob,os\n",
    "import peptides\n",
    "import warnings\n",
    "\n",
    "# define two reader funcitons\n",
    "def read_fasta(fasta_file):\n",
    "    content = {}\n",
    "    fas = open(fasta_file,'r')\n",
    "    seq = ''\n",
    "    last_entry = ''\n",
    "    while True:\n",
    "        line = fas.readline()\n",
    "        if len(line)==0:\n",
    "            content[last_entry]=seq\n",
    "            break\n",
    "        if '>' in line:\n",
    "            if last_entry=='':\n",
    "                line = line.rstrip()\n",
    "                last_entry=line\n",
    "            else:\n",
    "                line = line.rstrip()\n",
    "                content[last_entry]=seq\n",
    "                last_entry=line\n",
    "                seq=''\n",
    "        else:\n",
    "            line = line.rstrip()\n",
    "            seq += line\n",
    "    return content\n",
    "\n",
    "def flDPnn_reader(filename):\n",
    "    f=open(filename,'r')\n",
    "    flDPnn_dict ={}\n",
    "    header = ''\n",
    "    while True:\n",
    "        line = f.readline().rstrip()\n",
    "        if len(line)==0:\n",
    "            break\n",
    "        if line.startswith('>'):\n",
    "            header = line[1:11]\n",
    "            entry = []\n",
    "            if header not in flDPnn_dict:\n",
    "                for i in range(11):\n",
    "                    entry.append(f.readline().rstrip().split(','))\n",
    "                flDPnn_dict[header] = entry \n",
    "    return flDPnn_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dd7f8b-539d-47b4-b946-f494c73dd4e0",
   "metadata": {},
   "source": [
    "### Load selected ortholog table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a401cb1a-09fb-49ca-aaa8-26234c77d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "ortho_table = pd.read_csv('/Users/jzrolling/Desktop/Projects/HSPH/BacPROTAC/Final_draft/Tables/union_ortho_table_filtered.csv').drop(columns=['Unnamed: 0']).set_index('gene')\n",
    "ortho_table['Locus']=ortho_table.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d30659-e9c3-4e93-8774-f61beaeb5639",
   "metadata": {},
   "source": [
    "### Download AlphaFold data for selected Msm homologs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2733590c-bd6e-42e3-9599-0f9a0096824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve alphafold data\n",
    "import os,glob\n",
    "msm_proteome = pd.read_excel('/Users/jzrolling/Desktop/Projects/HSPH/BacPROTAC/Important_references/Msm_proteome_20230816.xlsx')\n",
    "msm_proteome['Locus'] = msm_proteome['Gene Names'].str.extract(r'(MSMEG_\\d+)')#Create new column with just locus\n",
    "msm_proteome.set_index('Locus',inplace=True)\n",
    "msm_proteome['Locus'] = msm_proteome.index\n",
    "msm_proteome_ingroup = msm_proteome.loc[ortho_table['Locus'].values].copy()\n",
    "\n",
    "# downloading AF data\n",
    "for x in msm_proteome_ingroup['Entry'].values:\n",
    "    pdb_file = 'https://alphafold.ebi.ac.uk/files/AF-{}-F1-model_v4.pdb'.format(x)\n",
    "    pae_file = 'https://alphafold.ebi.ac.uk/files/AF-{}-F1-predicted_aligned_error_v4.json'.format(x)\n",
    "    cif_file = 'https://alphafold.ebi.ac.uk/files/AF-{}-F1-model_v4.cif'.format(x)\n",
    "    pdb_export = '/Users/jzrolling/Desktop/Projects/HSPH/BacPROTAC/Alphafold/{}.pdb'.format(x)\n",
    "    pae_export = '/Users/jzrolling/Desktop/Projects/HSPH/BacPROTAC/Alphafold/{}_pae.json'.format(x)\n",
    "    cif_export = '/Users/jzrolling/Desktop/Projects/HSPH/BacPROTAC/Alphafold/{}.cif'.format(x)\n",
    "    if (not os.path.isfile(pdb_export)) or (not os.path.isfile(pae_export)) or (not os.path.isfile(cif_export)):\n",
    "        os.system(f'curl {pdb_file} -o {pdb_export}')\n",
    "        os.system(f'curl {pae_file} -o {pae_export}')\n",
    "        os.system(f'curl {cif_file} -o {cif_export}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be579dec-be34-4362-aeca-bf98b716da2c",
   "metadata": {},
   "source": [
    "### flDPnn predictions were retrieved from webserver http://biomine.cs.vcu.edu/servers/flDPnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab47e67-da5b-4930-8637-a96ed8eae680",
   "metadata": {},
   "source": [
    "### Load protein features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9664fb23-0f5a-4b2c-8aa7-8c069bd0dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plddt = []\n",
    "prot_seq = []\n",
    "# Load features generated by Ernst, ignore sasa as it is not normalized by protein length\n",
    "msm_features = pd.read_csv('/Users/jzrolling/Desktop/Projects/HSPH/BacPROTAC/202308_BacPROTAC_prediction_model/Msm_proteome_feature_analysis.csv').drop(columns=['sasa'])\n",
    "ortho_table['uniprot_id'] = msm_proteome.loc[ortho_table.index]['Entry']\n",
    "#Add a locus column to the features df based on mapping uniprot ID\n",
    "entry_to_locus = dict(zip(msm_proteome['Entry'], msm_proteome['Locus']))\n",
    "msm_features['locus'] = msm_features['uniprot_id'].copy().map(entry_to_locus)\n",
    "\n",
    "\n",
    "# load plDDT raw data\n",
    "for i,(uid,l) in enumerate(ortho_table[['uniprot_id','Locus']].values):\n",
    "    m = MMCIF2Dict('/Users/jzrolling/Desktop/Projects/HSPH/BacPROTAC/Alphafold/{}.cif'.format(uid))\n",
    "    plddt.append(np.array(m['_ma_qa_metric_local.metric_value']).astype(float))\n",
    "ortho_table['pLDDT_raw'] = plddt\n",
    "\n",
    "#load fLDPnn data\n",
    "flDPnn_dict = {}\n",
    "for f in sorted(glob.glob('/Users/jzrolling/Desktop/Projects/HSPH/BacPROTAC/Important_references/flDPnn/*.csv')):\n",
    "    flDPnn_dict.update(flDPnn_reader(f))\n",
    "\n",
    "# flDPnn disordered domain prediction\n",
    "ortho_table['flDPnn_disorder_propensity'] = [np.array(flDPnn_dict[x][2]).astype(float) for x in ortho_table['Locus'].values]\n",
    "\n",
    "\n",
    "# load AF features generated by Ernst\n",
    "g_features = []\n",
    "for x in ortho_table['Locus'].values:\n",
    "    if x in msm_features['locus'].values and 'MSMEG' in x: \n",
    "        subset = msm_features[msm_features['locus']==x]\n",
    "        g_features.append(subset[msm_features.columns[1:-1]].values[0])\n",
    "ortho_table[msm_features.columns[1:-1]] = np.array(g_features)\n",
    "\n",
    "#calculate full length protein peptide feature stats\n",
    "full_feature = pd.DataFrame([peptides.Peptide(s).descriptors() for s in ortho_table['Msm_seq'].values])\n",
    "ortho_table[['Full_{}'.format(x) for x in full_feature.columns]] = full_feature.values\n",
    "\n",
    "\n",
    "#calculate full length protein stats\n",
    "for f in ['flDPnn_disorder_propensity','pLDDT_raw']:\n",
    "    #ortho_table['{}_max'.format(f.split('_')[0])] = [x.min() for x in ortho_table[f].values]\n",
    "    ortho_table['{}_mean'.format(f.split('_')[0])] = [x.mean() for x in ortho_table[f].values]\n",
    "    #ortho_table['{}_median'.format(f.split('_')[0])] = [np.median(x) for x in ortho_table[f].values]\n",
    "    #ortho_table['{}_Q1'.format(f.split('_')[0])] = [np.percentile(x,25) for x in ortho_table[f].values]\n",
    "    #ortho_table['{}_Q3'.format(f.split('_')[0])] = [np.percentile(x,75) for x in ortho_table[f].values]\n",
    "    #ortho_table['{}_IQR'.format(f.split('_')[0])] = [np.percentile(x,75)-np.percentile(x,25) for x in ortho_table[f].values]\n",
    "    ortho_table['{}_STD'.format(f.split('_')[0])] = [np.std(x) for x in ortho_table[f].values]\n",
    "    if f=='flDPnn_disorder_propensity':\n",
    "        ortho_table['{}>0.2_count'.format(f.split('_')[0])] = [(x>0.2).sum() for x in ortho_table[f].values]\n",
    "        ortho_table['{}>0.2_frac'.format(f.split('_')[0])] = [(x>0.2).sum()/len(x) for x in ortho_table[f].values]\n",
    "        ortho_table['{}>0.5_frac'.format(f.split('_')[0])] = [(x>0.5).sum()/len(x) for x in ortho_table[f].values]\n",
    "        ortho_table['{}>0.5_count'.format(f.split('_')[0])] = [(x>0.5).sum() for x in ortho_table[f].values]\n",
    "    \n",
    "\n",
    "for term_length in [15,30]:\n",
    "    # terminal sequence peptide features\n",
    "    nterm = [x[:term_length] for x in ortho_table['Msm_seq'].values]\n",
    "    cterm = [x[-term_length:] for x in ortho_table['Msm_seq'].values]\n",
    "    nterm_feature = pd.DataFrame([peptides.Peptide(s).descriptors() for s in nterm])\n",
    "    cterm_feature = pd.DataFrame([peptides.Peptide(s).descriptors() for s in cterm])\n",
    "    ortho_table[['Nterm{}_{}'.format(term_length,x) for x in nterm_feature.columns]] = nterm_feature.values\n",
    "    ortho_table[['Cterm{}_{}'.format(term_length,x) for x in cterm_feature.columns]] = cterm_feature.values\n",
    "\n",
    "    # calculate terminal disorderedness and pLDDT stats\n",
    "    for f in ['flDPnn_disorder_propensity','pLDDT_raw']:\n",
    "        #ortho_table['Nterm{}_{}_min'.format(term_length,f.split('_')[0])] = [x[:term_length].min() for x in ortho_table[f].values]\n",
    "        ortho_table['Nterm{}_{}_mean'.format(term_length,f.split('_')[0])] = [x[:term_length].mean() for x in ortho_table[f].values]\n",
    "        #ortho_table['Nterm{}_{}_median'.format(term_length,f.split('_')[0])] = [np.median(x[:term_length]) for x in ortho_table[f].values]\n",
    "        #ortho_table['Nterm{}_{}_Q1'.format(term_length,f.split('_')[0])] = [np.percentile(x[:term_length],25) for x in ortho_table[f].values]\n",
    "        #ortho_table['Nterm{}_{}_Q3'.format(term_length,f.split('_')[0])] = [np.percentile(x[:term_length],75) for x in ortho_table[f].values]\n",
    "        #ortho_table['Nterm{}_{}_IQR'.format(term_length,f.split('_')[0])] = [np.percentile(x[:term_length],75)-np.percentile(x[:term_length],25) for x in ortho_table[f].values]\n",
    "        ortho_table['Nterm{}_{}_std'.format(term_length,f.split('_')[0])] = [np.std(x[:term_length]) for x in ortho_table[f].values]\n",
    "        #ortho_table['Cterm{}_{}_min'.format(term_length,f.split('_')[0])] = [x[-term_length:].min() for x in ortho_table[f].values]\n",
    "        ortho_table['Cterm{}_{}_mean'.format(term_length,f.split('_')[0])] = [x[-term_length:].mean() for x in ortho_table[f].values]\n",
    "        #ortho_table['Cterm{}_{}_median'.format(term_length,f.split('_')[0])] = [np.median(x[-term_length:]) for x in ortho_table[f].values]\n",
    "        #ortho_table['Cterm{}_{}_Q1'.format(term_length,f.split('_')[0])] = [np.percentile(x[-term_length:],25) for x in ortho_table[f].values]\n",
    "        #ortho_table['Cterm{}_{}_Q3'.format(term_length,f.split('_')[0])] = [np.percentile(x[-term_length:],75) for x in ortho_table[f].values]\n",
    "        #ortho_table['Cterm{}_{}_IQR'.format(term_length,f.split('_')[0])] = [np.percentile(x[-term_length:],75)-np.percentile(x[-term_length:],25) for x in ortho_table[f].values]\n",
    "        ortho_table['Cterm{}_{}_std'.format(term_length,f.split('_')[0])] = [np.std(x[-term_length:]) for x in ortho_table[f].values]\n",
    "        if f=='flDPnn_disorder_propensity':\n",
    "            ortho_table['Nterm{}_{}>0.2_frac'.format(term_length,f.split('_')[0])] = [(x[:term_length]>0.2).sum()/term_length for x in ortho_table[f].values]\n",
    "            ortho_table['Cterm{}_{}>0.2_frac'.format(term_length,f.split('_')[0])] = [(x[-term_length:]>0.2).sum()/term_length for x in ortho_table[f].values]\n",
    "        if f=='pLDDT_raw':\n",
    "            ortho_table['Nterm{}_{}<50_frac'.format(term_length,f.split('_')[0])] = [(x[:term_length]<50).sum()/term_length for x in ortho_table[f].values]\n",
    "            ortho_table['Cterm{}_{}<50_frac'.format(term_length,f.split('_')[0])] = [(x[-term_length:]<50).sum()/term_length for x in ortho_table[f].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4491b-1f2b-4753-bb2a-3f59555b0e5c",
   "metadata": {},
   "source": [
    "### Save protein features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0144cddf-fcfb-41fa-8b69-09375c16bb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ortho_table.to_csv('/Users/jzrolling/Desktop/Projects/HSPH/BacPROTAC/Final_draft/Tables/union_ortho_table_withFeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b8465eb0-1157-4739-b2c3-b9b2f40556f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "pk.dump(ortho_table,open('/Users/jzrolling/Desktop/Projects/HSPH/BacPROTAC/Final_draft/Tables/union_ortho_table_withFeatures.pk','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44378721-6327-4964-bad1-331b7051e53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
